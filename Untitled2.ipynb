{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRVrpU+9c+m4xF2ON/Qi3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedramasl/CameraCalibration/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsY3xTTpHBVm",
        "outputId": "a1f8cfee-371f-457c-9c59-5accdddbeb8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 60, 50)            10400     \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 60, 50)            20200     \n",
            "                                                                 \n",
            " permute_6 (Permute)         (None, 50, 60)            0         \n",
            "                                                                 \n",
            " reshape_6 (Reshape)         (None, 50, 60)            0         \n",
            "                                                                 \n",
            " permute_7 (Permute)         (None, 60, 50)            0         \n",
            "                                                                 \n",
            " reshape_7 (Reshape)         (None, 60, 50)            0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 3000)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3001      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1)                 0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 1)                 4         \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33605 (131.27 KB)\n",
            "Trainable params: 33603 (131.26 KB)\n",
            "Non-trainable params: 2 (8.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 7s 96ms/step - loss: 0.5201 - val_loss: 0.3946\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2759 - val_loss: 0.3560\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.2460 - val_loss: 0.3304\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.2268 - val_loss: 0.3058\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.2070 - val_loss: 0.2754\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1848 - val_loss: 0.2536\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.1670 - val_loss: 0.2275\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1491 - val_loss: 0.2082\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.1338 - val_loss: 0.1921\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.1204 - val_loss: 0.1627\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.1089 - val_loss: 0.1543\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0961 - val_loss: 0.1484\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 4s 145ms/step - loss: 0.0881 - val_loss: 0.1316\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.0768 - val_loss: 0.1145\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0700 - val_loss: 0.0993\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0610 - val_loss: 0.0747\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 2s 72ms/step - loss: 0.0549 - val_loss: 0.0697\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.0494 - val_loss: 0.0648\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.0451 - val_loss: 0.0663\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 2s 86ms/step - loss: 0.0397 - val_loss: 0.0541\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 2s 86ms/step - loss: 0.0348 - val_loss: 0.0552\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0309 - val_loss: 0.0403\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0299 - val_loss: 0.0418\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 0.0255 - val_loss: 0.0272\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.0225 - val_loss: 0.0217\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0204 - val_loss: 0.0271\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0167 - val_loss: 0.0252\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 2s 82ms/step - loss: 0.0214 - val_loss: 0.0235\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 3s 101ms/step - loss: 0.0167 - val_loss: 0.0014\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0170 - val_loss: 0.0115\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.0140 - val_loss: 0.0128\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0142 - val_loss: 0.0055\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.0150 - val_loss: 0.0031\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0156 - val_loss: 0.0075\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0145 - val_loss: 0.0125\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 2s 67ms/step - loss: 0.0119 - val_loss: 0.0107\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 2s 100ms/step - loss: 0.0117 - val_loss: 0.0044\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.0124 - val_loss: 0.0039\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 2s 62ms/step - loss: 0.0129 - val_loss: 0.0127\n",
            "Epoch 1/100\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 0.0115 - val_loss: 0.0012 - lr: 0.0010\n",
            "Epoch 2/100\n",
            " 2/25 [=>............................] - ETA: 1s - loss: 0.0125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0117 - val_loss: 0.0154 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0110 - val_loss: 0.0133 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.0109 - val_loss: 0.0014 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 0.0093 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 2s 92ms/step - loss: 0.0113 - val_loss: 0.0039 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0119 - val_loss: 0.0051 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0101 - val_loss: 0.0013 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0103 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0110 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0110 - val_loss: 0.0030 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.0085 - val_loss: 0.0020 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.0099 - val_loss: 0.0010 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 2s 99ms/step - loss: 0.0085 - val_loss: 0.0013 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 0.0093 - val_loss: 0.0017 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0073 - val_loss: 0.0015 - lr: 1.0000e-05\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0106 - val_loss: 0.0015 - lr: 1.0000e-05\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0084 - val_loss: 0.0016 - lr: 1.0000e-05\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0104 - val_loss: 0.0015 - lr: 1.0000e-05\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.0083 - val_loss: 0.0017 - lr: 1.0000e-05\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.0110 - val_loss: 0.0017 - lr: 1.0000e-06\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 2s 91ms/step - loss: 0.0101 - val_loss: 0.0016 - lr: 1.0000e-06\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 0.0106 - val_loss: 0.0016 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "aapl_data = yf.download('AAPL', start='2020-01-01', end='2024-01-01')\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "aapl_data_scaled = scaler.fit_transform(aapl_data['Close'].values.reshape(-1,1))\n",
        "aapl_data_scaled\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(60, len(aapl_data_scaled)):\n",
        "    X.append(aapl_data_scaled[i-60:i, 0])\n",
        "    y.append(aapl_data_scaled[i, 0])\n",
        "train_size = int(len(X) * 0.8)\n",
        "test_size = len(X) - train_size\n",
        "\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout, AdditiveAttention, Permute, Reshape, Multiply\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Adding LSTM layers with return_sequences=True\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "# Adding self-attention mechanism\n",
        "# The attention mechanism\n",
        "attention = AdditiveAttention(name='attention_weight')\n",
        "# Permute and reshape for compatibility\n",
        "model.add(Permute((2, 1)))\n",
        "model.add(Reshape((-1, X_train.shape[1])))\n",
        "attention_result = attention([model.output, model.output])\n",
        "multiply_layer = Multiply()([model.output, attention_result])\n",
        "# Return to original shape\n",
        "model.add(Permute((2, 1)))\n",
        "model.add(Reshape((-1, 50)))\n",
        "\n",
        "# Adding a Flatten layer before the final Dense layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Final Dense layer\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "#history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# Adding Dropout and Batch Normalization\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n",
        "# history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2)\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=[early_stopping])\n",
        "# Callback to save the model periodically\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Callback to reduce learning rate when a metric has stopped improving\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "# Callback for TensorBoard\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "# Callback to log details to a CSV file\n",
        "csv_logger = CSVLogger('training_log.csv')\n",
        "\n",
        "# Combining all callbacks\n",
        "callbacks_list = [early_stopping, model_checkpoint, reduce_lr, tensorboard, csv_logger]\n",
        "\n",
        "# Fit the model with the callbacks\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=25, validation_split=0.2, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert X_test and y_test to Numpy arrays if they are not already\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Ensure X_test is reshaped similarly to how X_train was reshaped\n",
        "# This depends on how you preprocessed the training data\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Now evaluate the model on the test data\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss: \", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gOdj7E7UDM",
        "outputId": "3776351d-c931-4ea6-fbb9-6ab1ddca11d0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0086\n",
            "Test Loss:  0.008649077266454697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Making predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculating MAE and RMSE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "print(\"Mean Absolute Error: \", mae)\n",
        "print(\"Root Mean Square Error: \", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ5jUTtk7rgR",
        "outputId": "47f68895-72cc-425c-87b2-dccee44503c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 4s 46ms/step\n",
            "Mean Absolute Error:  0.08864725892017007\n",
            "Root Mean Square Error:  0.09300041282170642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Fetching the latest 60 days of AAPL stock data\n",
        "data = yf.download('AAPL', period='3mo', interval='1d')\n",
        "\n",
        "# Selecting the 'Close' price and converting to numpy array\n",
        "closing_prices = data['Close'].values\n",
        "\n",
        "# Scaling the data\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_data = scaler.fit_transform(closing_prices.reshape(-1,1))\n",
        "\n",
        "# Since we need the last 60 days to predict the next day, we reshape the data accordingly\n",
        "X_latest = np.array([scaled_data[-60:].reshape(60)])\n",
        "\n",
        "# Reshaping the data for the model (adding batch dimension)\n",
        "X_latest = np.reshape(X_latest, (X_latest.shape[0], X_latest.shape[1], 1))\n",
        "\n",
        "# Making predictions for the next 4 candles\n",
        "predicted_stock_price = model.predict(X_latest)\n",
        "predicted_stock_price = scaler.inverse_transform(predicted_stock_price)\n",
        "\n",
        "print(\"Predicted Stock Prices for the next 4 days: \", predicted_stock_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmLBMqhi-u1p",
        "outputId": "5177122d-a3c7-4d3f-e0c7-56f9e496f230"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted Stock Prices for the next 4 days:  [[213.53835]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}